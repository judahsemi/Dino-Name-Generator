{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.functional import F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate\n",
    "from utils import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_re = torch.load(\"./saves/data/clean_names.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_char = data_dict_re[\"data_in_char\"]\n",
    "char_vocab = data_dict_re[\"char_vocab\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** `char_vocab` contains a **PAD token** which is meant for when we want to batch our training data. We are not doing that here, so we are removing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"<PAD>\" in char_vocab:\n",
    "    char_vocab.remove(\"<PAD>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data length:\", len(data_in_char))\n",
    "print(\"vocab size:\", len(char_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(data_in_char[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix = {ch:i for i,ch in enumerate(char_vocab)}\n",
    "ix_to_char = {i:ch for ch,i in char_to_ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_as_str, _map):\n",
    "        self.data_as_int = []\n",
    "        self.max_seqlen = float(\"-inf\")\n",
    "        self.min_seqlen = float(\"inf\")\n",
    "        \n",
    "        # Convert characters to integers\n",
    "        for seq_as_str in data_as_str:\n",
    "            seq_as_int = evaluate.keys_to_values(seq_as_str, _map,\n",
    "                random.choice(list(_map)))\n",
    "            \n",
    "            self.data_as_int.append(seq_as_int)\n",
    "            self.max_seqlen = max(self.max_seqlen, len(seq_as_int)-1)\n",
    "            self.min_seqlen = min(self.min_seqlen, len(seq_as_int)-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_as_int)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        # Get data sample at index ix\n",
    "        item = self.data_as_int[ix]\n",
    "        \n",
    "        # Slice x and y from sample\n",
    "        x = item[:-1]\n",
    "        y = item[ 1:]\n",
    "        \n",
    "        return torch.tensor(x), torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(data_in_char, char_to_ix)\n",
    "dataloader = DataLoader(dataset, 1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Max sequence length:\", dataset.max_seqlen)\n",
    "print(\"Min sequence length:\", dataset.min_seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, _map, hidden_size, emb_dim=8, n_layers=1, dropout_p=0.2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            _map: char_to_ix.\n",
    "            hidden_size: Number of features to learn.\n",
    "            emb_dim: Size of embedding vector.\n",
    "            n_layers: Number of layers.\n",
    "            dropout_p: Dropout probability.\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.vocab_size  = len(_map)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_dim     = emb_dim\n",
    "        self.n_layers    = n_layers\n",
    "        self.dropout_p   = dropout_p\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=self.vocab_size,\n",
    "            embedding_dim =self.emb_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size =self.emb_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers =self.n_layers,\n",
    "            batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            in_features =self.hidden_size,\n",
    "            out_features=self.vocab_size)\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            x: x\n",
    "            prev_state: The previous state of the model.\n",
    "            \n",
    "        Output:\n",
    "            out: The output of the model.\n",
    "            state: The current state of the model.\n",
    "        \"\"\"\n",
    "        n_b, n_s = x.shape\n",
    "        \n",
    "        embed = self.embedding(x)\n",
    "        yhat, state = self.lstm(embed, prev_state)\n",
    "        \n",
    "        yhat = self.dropout(yhat)\n",
    "        out = self.fc(yhat)\n",
    "        return out, state\n",
    "    \n",
    "    def init_state(self, b_size=1):\n",
    "        return (torch.zeros(self.n_layers, b_size, self.hidden_size),\n",
    "                torch.zeros(self.n_layers, b_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Model(char_to_ix, 64, 8, n_layers=1, dropout_p=0.2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    m_data = torch.load(path)\n",
    "    \n",
    "    m = Model(\n",
    "        _map       =m_data[\"_map\"],\n",
    "        hidden_size=m_data[\"hidden_size\"],\n",
    "        emb_dim    =m_data[\"emb_dim\"],\n",
    "        n_layers   =m_data[\"n_layers\"],\n",
    "        dropout_p  =m_data[\"dropout_p\"])\n",
    "    \n",
    "    m.load_state_dict(m_data[\"state_dict\"])\n",
    "    l_hist = m_data[\"loss_history\"]\n",
    "    return m, l_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uncomment cell to load the trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, loss_history = load_model(\"./saves/model/dino-name.pt\")\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, l_hist, _map, path=None):\n",
    "    if not path: path = \"./saves/model/dino-name.pt\"\n",
    "        \n",
    "    m_data = {\n",
    "        \"_map\"        : _map,\n",
    "        \"hidden_size\" : m.hidden_size,\n",
    "        \"emb_dim\"     : m.emb_dim,\n",
    "        \"n_layers\"    : m.n_layers,\n",
    "        \"dropout_p\"   : m.dropout_p,\n",
    "        \"state_dict\"  : m.state_dict(),\n",
    "        \"loss_history\": l_hist}\n",
    "    torch.save(m_data, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iteration = 50000\n",
    "per_iter = 5000\n",
    "start_t = time.time()\n",
    "\n",
    "for _ti in range(iteration//per_iter):\n",
    "    model, costs = training.train(\n",
    "        model, dataloader, per_iter, criterion, clip=0.25, lr=1e-3, print_every=1000)\n",
    "    \n",
    "    loss_history.extend(costs)\n",
    "    save_model(model, loss_history, char_to_ix)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Round: {:2} of {:2}, Running Time: {:7.2f} sec\".format(\n",
    "        _ti+1, iteration//per_iter, time.time() - start_t))\n",
    "    print(\"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cum = 250\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cross-Entropy Loss\")\n",
    "plt.plot(\n",
    "    [sum(loss_history[i:i+cum])/cum for i in range(0, len(loss_history), cum)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Iter: {} | Min: {:.4f} | Max: {:.4f} | Last: {:.4f} | Ave: {:.4f}\".format(\n",
    "    len(loss_history), min(loss_history), max(loss_history), loss_history[-1],\n",
    "    sum(loss_history)/len(loss_history)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samp = 100\n",
    "ix_list = list(char_to_ix.values())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originality = evaluate.originality(\n",
    "    n_samp, dataset.data_as_int, evaluate.sample, model, ix_list,\n",
    "    4, False, dataset.max_seqlen, char_to_ix[\"<EOS>\"], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise sampling with a **randomly chosen character**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    seed = random.choice(ix_list)\n",
    "    \n",
    "    print(ix_to_char[seed], \"=>\", \"\".join(evaluate.keys_to_values(\n",
    "        evaluate.sample(model, seed, 5, False, 30, char_to_ix[\"<EOS>\"], False),\n",
    "        ix_to_char, \"<?>\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise sampling with **a list of characters** instead of a single character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    word = \"python\"\n",
    "    seed = evaluate.keys_to_values(list(word), char_to_ix, char_to_ix[\"<EOS>\"])\n",
    "    \n",
    "    print(word, \"=>\", \"\".join(evaluate.keys_to_values(\n",
    "        evaluate.sample(model, seed, 5, False, 30, char_to_ix[\"<EOS>\"], False),\n",
    "        ix_to_char, \"<?>\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the next **most likely character** instead of the next **topk most likely characters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ch in char_vocab:\n",
    "    seed = char_to_ix[ch]\n",
    "    \n",
    "    print(\"{:->5}\".format(ch), \"=>\", \"\".join(evaluate.keys_to_values(\n",
    "        evaluate.sample(model, seed, 1, True, 30, char_to_ix[\"<EOS>\"], False),\n",
    "        ix_to_char, \"<?>\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
