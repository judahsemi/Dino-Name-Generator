{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.functional import F\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate\n",
    "from utils import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict_re = torch.load(\"./saves/data/clean_names.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_char = data_dict_re[\"data_in_char\"]\n",
    "char_vocab = data_dict_re[\"char_vocab\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data length:\", len(data_in_char))\n",
    "print(\"vocab size:\", len(char_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(data_in_char[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ix = {ch:i for i,ch in enumerate(char_vocab)}\n",
    "ix_to_char = {i:ch for ch,i in char_to_ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_as_str, _map, batched):\n",
    "        self.batched = batched\n",
    "        \n",
    "        self.data_as_int = []\n",
    "        self.max_seqlen = float(\"-inf\")\n",
    "        self.min_seqlen = float(\"inf\")\n",
    "        \n",
    "        # Convert data to integers\n",
    "        for seq_as_str in data_as_str:\n",
    "            seq_as_int = evaluate.keys_to_values(seq_as_str, _map,\n",
    "                random.choice(list(_map)))\n",
    "            \n",
    "            self.data_as_int.append(seq_as_int)\n",
    "            self.max_seqlen = max(self.max_seqlen, len(seq_as_int)-1)\n",
    "            self.min_seqlen = min(self.min_seqlen, len(seq_as_int)-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_as_int)\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        # Get data sample at index, ix\n",
    "        item = self.data_as_int[ix]\n",
    "        PAD_ix = char_to_ix[\"<PAD>\"]\n",
    "        \n",
    "        # Slice x and y from sample\n",
    "        x_pad = item[:-1]\n",
    "        x_len = len(x_pad)\n",
    "        y_pad = item[ 1:]\n",
    "        \n",
    "        # Pad x and y to self.max_seqlen, if self.batched is True\n",
    "        if self.batched:\n",
    "            x_pad += ([PAD_ix] * (self.max_seqlen - len(x_pad)))\n",
    "            y_pad += ([PAD_ix] * (self.max_seqlen - len(y_pad)))\n",
    "            \n",
    "        return (torch.tensor(x_pad), torch.tensor(x_len)), torch.tensor(y_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset(data_in_char, char_to_ix, batched=True)\n",
    "dataloader = DataLoader(dataset, 16, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset size:\", len(dataset))\n",
    "print(\"Max sequence length:\", dataset.max_seqlen)\n",
    "print(\"Min sequence length:\", dataset.min_seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, _map, hidden_size, emb_dim=8, n_layers=1, dropout_p=0.2):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            _map: char_to_ix.\n",
    "            hidden_size: Number of features to learn.\n",
    "            emb_dim: Size of embedding vector.\n",
    "            n_layers: Number of layers.\n",
    "            dropout_p: Dropout probability.\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.vocab_size  = len(_map)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.emb_dim     = emb_dim\n",
    "        self.n_layers    = n_layers\n",
    "        self.dropout_p   = dropout_p\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=self.vocab_size,\n",
    "            embedding_dim =self.emb_dim,\n",
    "            padding_idx   =_map[\"<PAD>\"])\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size =self.emb_dim,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers =self.n_layers,\n",
    "            batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            in_features =self.hidden_size,\n",
    "            out_features=self.vocab_size)\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            x: (x, x_len)\n",
    "            prev_state: The previous state.\n",
    "            \n",
    "        Output:\n",
    "            out: The output of the model.\n",
    "            state: The current state.\n",
    "        \"\"\"\n",
    "        n_b, n_s = x[0].shape\n",
    "        batched = True if (n_b>1 or len(x)>1) else False\n",
    "        \n",
    "        embed = self.embedding(x[0])\n",
    "        \n",
    "        # Pack-pad embeddings if x is batched\n",
    "        if batched:\n",
    "            embed = nn.utils.rnn.pack_padded_sequence(\n",
    "                embed, x[1], True, False)\n",
    "            \n",
    "        yhat, state = self.lstm(embed, prev_state)\n",
    "        \n",
    "        # Un-pack-pad the lstm output\n",
    "        if batched:\n",
    "            yhat, _ = nn.utils.rnn.pad_packed_sequence(\n",
    "                yhat, True, total_length=n_s)\n",
    "            \n",
    "        yhat = self.dropout(yhat)\n",
    "        out = self.fc(yhat)\n",
    "        return out, state\n",
    "    \n",
    "    def init_state(self, b_size=1):\n",
    "        return (torch.zeros(self.n_layers, b_size, self.hidden_size),\n",
    "                torch.zeros(self.n_layers, b_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Model(char_to_ix, 64, 8, n_layers=1, dropout_p=0.2)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    m_data = torch.load(path)\n",
    "    \n",
    "    m = Model(\n",
    "        _map       =m_data[\"_map\"],\n",
    "        hidden_size=m_data[\"hidden_size\"],\n",
    "        emb_dim    =m_data[\"emb_dim\"],\n",
    "        n_layers   =m_data[\"n_layers\"],\n",
    "        dropout_p  =m_data[\"dropout_p\"])\n",
    "    \n",
    "    m.load_state_dict(m_data[\"state_dict\"])\n",
    "    l_hist = m_data[\"loss_history\"]\n",
    "    return m, l_hist, _map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uncomment cell to load the trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, losss_history = load_model(\"./saves/model/dino-name.pt\")\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, l_hist, _map, path=None):\n",
    "    if not path: path = \"./saves/model/dino-name_batch.pt\"\n",
    "        \n",
    "    m_data = {\n",
    "        \"_map\"        : _map,\n",
    "        \"hidden_size\" : m.hidden_size,\n",
    "        \"emb_dim\"     : m.emb_dim,\n",
    "        \"n_layers\"    : m.n_layers,\n",
    "        \"dropout_p\"   : m.dropout_p,\n",
    "        \"state_dict\"  : m.state_dict(),\n",
    "        \"loss_history\": l_hist}\n",
    "    torch.save(m_data, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=char_to_ix[\"<PAD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iteration = 250\n",
    "per_iter = 50\n",
    "start_t = time.time()\n",
    "\n",
    "for _ti in range(iteration//per_iter):\n",
    "    model, costs = training.train(\n",
    "        model, dataloader, per_iter, criterion, clip=0.25, lr=1e-3, print_every=10,\n",
    "        sleep=5, sleep_every=25)\n",
    "    \n",
    "    loss_history.extend(costs)\n",
    "    save_model(model, loss_history, char_to_ix)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Round: {:2} of {:2}, Running Time: {:7.2f} sec\".format(\n",
    "        _ti+1, iteration//per_iter, time.time() - start_t))\n",
    "    print(\"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cum = 5\n",
    "plt.plot(\n",
    "    [sum(loss_history[i:i+cum])/cum for i in range(0, len(loss_history), cum)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Iter: {} | Min: {:.4f} | Max: {:.4f} | Last: {:.4f} | Ave: {:.4f}\".format(\n",
    "    len(loss_history), min(loss_history), max(loss_history), loss_history[-1],\n",
    "    sum(loss_history)/len(loss_history)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samp = 100\n",
    "ix_list = list(char_to_ix.values())[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originality = evaluate.originality(\n",
    "    n_samp, dataset.data_as_int, evaluate.sample, model, ix_list,\n",
    "    4, False, 30, char_to_ix[\"<EOS>\"])\n",
    "\n",
    "print(\"Duplicates: {} of {}\".format(len(originality[1]), n_samp))\n",
    "print(\"{:6.2f}% recall\".format(100 * len(originality[1]) / n_samp))\n",
    "print(\"{:6.2f}% original\".format(100 - (100 * len(originality[1]) / n_samp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"\".join(evaluate.keys_to_values(\n",
    "        evaluate.sample(\n",
    "            model, random.choice(ix_list), 5, False, 30, char_to_ix[\"<EOS>\"]),\n",
    "        ix_to_char, \"<?>\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"\".join(evaluate.keys_to_values(\n",
    "        evaluate.sample(\n",
    "            model, evaluate.keys_to_values(\n",
    "                list(\"giant\"), char_to_ix, char_to_ix[\"<PAD>\"]\n",
    "            ), 5, False, 30, char_to_ix[\"<EOS>\"]),\n",
    "        ix_to_char, \"<?>\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ch in char_vocab:\n",
    "    print(\"\".join(evaluate.keys_to_values(\n",
    "        evaluate.sample(\n",
    "            model, char_to_ix[ch], 1, True, 30, char_to_ix[\"<EOS>\"]),\n",
    "        ix_to_char, \"<?>\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
